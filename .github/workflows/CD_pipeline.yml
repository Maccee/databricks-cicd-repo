name: CD Pipeline for Azure Databricks

on:
  push:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
    # Step 1: Checkout Code
    - name: Checkout code
      uses: actions/checkout@v3

    # Step 2: Set up Python Environment
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    # Step 3: Install Databricks CLI
    - name: Install Databricks CLI
      run: |
        pip install databricks-cli jq

    # Step 4: Configure Databricks CLI
    - name: Configure Databricks CLI
      env:
        DATABRICKS_HOST: https://adb-2645810494232482.2.azuredatabricks.net
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
      run: |
        echo -e "$DATABRICKS_HOST\n$DATABRICKS_TOKEN" | databricks configure --token

    # Step 5: Upload Notebook to DBFS
    - name: Upload Notebook to DBFS
      env:
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
      run: |
        databricks fs cp sample_sales_notebook.dbc dbfs:/Workspace/Users/marcus.hasselgren@devisioona.fi/Databricks/Implement_CICD_workflows/sample_sales_notebook --overwrite

    # Step 6: Create and Run Databricks Job
    - name: Create and Run Databricks Job
      env:
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
      run: |
        # Create the job and capture the job ID
        RESPONSE=$(databricks jobs create --json-file job-config.json)
        echo "Job Creation Response: $RESPONSE"
        JOB_ID=$(echo $RESPONSE | jq -r '.job_id')

        # Validate the job ID
        if [ -z "$JOB_ID" ] || [ "$JOB_ID" = "null" ]; then
          echo "Error: Job ID could not be extracted"
          exit 1
        fi

        echo "Created Job ID: $JOB_ID"

        # Run the job
        RUN_RESPONSE=$(databricks jobs run-now --job-id "$JOB_ID")
        echo "Job Run Response: $RUN_RESPONSE"
